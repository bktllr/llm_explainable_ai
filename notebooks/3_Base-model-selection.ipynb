{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf7d6ac-c018-41db-be28-a35f7b264253",
   "metadata": {},
   "source": [
    "# Base model selection\n",
    "\n",
    "Within the base model selection, we decided to go with the Llama-2-series of meta as it currently (as of November 2023) consists of the best open source models available. Thereby, we selected the chat-series as we want our chatbot to be optimized for chat-use-cases at the end as well. Within this series we had to decide between 7b, 13b and 70b variant. We decided to use the 13B variant as this variant represents a good trade-off between quality and efficiency compared to its 7B and 70B counterparts.\n",
    "\n",
    "## Downloading the Llama-2-model\n",
    "\n",
    "At first, we had to download the Llama-2-13B-chat-hf model into our text-generation-webui. Therefore, we used the following commands in the terminal:\n",
    "\n",
    "    cd /home/[...]/text-generation-webui/models/\n",
    "    mkdir Llama-2-13b-hf\n",
    "    cd /home/[...]/text-generation-webui/models/Llama-2-13b-hf/\n",
    "    wget https://huggingface.co/4bit/Llama-2-13b-chat-hf/resolve/main/model-00001-of-00003.safetensors\n",
    "    wget https://huggingface.co/4bit/Llama-2-13b-chat-hf/resolve/main/model-00002-of-00003.safetensors\n",
    "    wget https://huggingface.co/4bit/Llama-2-13b-chat-hf/resolve/main/model-00003-of-00003.safetensors\n",
    "    wget https://huggingface.co/4bit/Llama-2-13b-chat-hf/raw/main/model.safetensors.index.json\n",
    "    wget https://huggingface.co/4bit/Llama-2-13b-chat-hf/raw/main/special_tokens_map.json\n",
    "    wget https://huggingface.co/4bit/Llama-2-13b-chat-hf/resolve/main/tokenizer.model\n",
    "    wget https://huggingface.co/4bit/Llama-2-13b-chat-hf/raw/main/tokenizer_config.json\n",
    "    wget https://huggingface.co/4bit/Llama-2-13b-chat-hf/raw/main/config.json\n",
    "    wget https://huggingface.co/4bit/Llama-2-13b-chat-hf/raw/main/generation_config.json \n",
    "    \n",
    "The model is now stored within the folder \"/home/[...]/text-generation-webui/models/\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e1c912-0d02-4681-9986-584a1fd0d0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 - Cuda (ipykernel)",
   "language": "python",
   "name": "python3-jr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
