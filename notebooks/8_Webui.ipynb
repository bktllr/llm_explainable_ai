{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6012d60d-a7bd-4133-b550-c068263a8921",
   "metadata": {},
   "source": [
    "# Webui\n",
    "Lastly, we developed the Webui that combines all parts of the pipeline. Therefore, we firstly compared if Gradio or Strealit fits our purpose better.\n",
    "\n",
    "## Comparison of Gradio vs Streamlit\n",
    "\n",
    "Gradio and Streamlit both provide different widgets and functionalities to the user that he can use to create interactive webapps. In this regard, both frameworks perform similar. However, the deployment of the apps differs slightly. While on a local device both apps can be started easily by e.g. \"python gradio-app.py\" and \"streamlit run app.py\" and then copying the local URL into the browser, the deployment of the apps via a server is more complicated. \n",
    "\n",
    "### Gradio\n",
    "For the deployment from a server, gradio provides a simple external (public) link.\n",
    "\n",
    "Thereby, the frontend-webui is hosted on the gradio-server, the backend however remains on the originial server. This means that everyone can acces the webui over the external link on the gradio server, the generation of an answer in the case of a chatbot via a LLM however is still executed on the backend-server. Thereby, the generation of the answer is performed in an efficient and fast manner as the LLM can access the GPU-ressources. Looking at the security-aspect, the external URL can be secured by a password.\n",
    "\n",
    "### Streamlit\n",
    "In comparision to the gradio-app, the deployment of the streamlit-app is way more difficult from the server. Even though streamlit as well generates an external URL, this external URL is not hosted on another server, but is connected to the original server. \n",
    "\n",
    "Thereby, the problem appears that even though an URL is generated, the site cannot be reached from a local device (whyever?).\n",
    "\n",
    "A workaround that was tried to resolve this problem, was to build a local tunnel to the specific port. This is the solution that was proposed the deploy a streamlit app from google colab. However, while this solution works for google colab, it doesn't work for the jupyter lab. Even though we were able at some point to install nodejs and npm into the environment, npx still has problems that we weren't able to solve in a reasonable amount of time.\n",
    "\n",
    "Alternative approaches would be to deploy the streamlit app from a local device or from the community cloud. However, the deployment of the app from a local device would mean that we would also have to execute the ML- and LLM-models from our local device. This is not possible in a reasonable amount of time with the ressources, we have on our local devices. The second option would be to deploy the streamlit app over the community cloud. First tests, showed that deployment of the app over the community cloud results in a URL that can be at least reached. However, using the community cloud would mean that we would have to shift everything (not only the frontend as in the case of gradio) to the streamlit community cloud server what will be probably problematic from a security perspective. Furthermore, we would also have to shift the execution of the ML- and LLM-model to the community server. Thereby, we neither know if this is possible at all in the first place and in the second place, we don't know how many ressources we could use from the community server for the execution. In comparison, the execution of the ML- and LLM-Model in the gradio-case would be still on our server, where some ressources in the form of GPUs for sure exist.\n",
    "\n",
    "### Results\n",
    "\n",
    "Because of the problems we encountered in the deployment of the streamlit app from a server, we decide to go on with the gradio-framework.\n",
    "\n",
    "## Initialization of Gradio-Webui\n",
    "The gradio-webui was developed in the file webui.py in the folder \"/home/[...]/gradio-webui/\". The gradio-app can be started using the following commands in the terminal:\n",
    "\n",
    "    conda activate webui\n",
    "    cd /home/[...]/gradio-webui/\n",
    "    python webui.py\n",
    "\n",
    "Attention: If you want to use this gradio app, you have to enter your huggingface-token in line 13 in the document \"Webui.py\". Currently, the battery-model is connected with the webui. The alternative models can be connected via line 17-21.\n",
    "\n",
    "The gradio app runs on a local and public url. Copy the public url into your browser to access the webui. The credentials are auth=(\"admin\", \"admin\")."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
